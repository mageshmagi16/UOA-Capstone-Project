{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CAbziLnctSY",
        "outputId": "6da628e5-628e-4919-8104-b1329d6690ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycocotools\n",
            "  Using cached pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Collecting albumentations\n",
            "  Using cached albumentations-2.0.4-py3-none-any.whl (289 kB)\n",
            "Collecting matplotlib>=2.1.0 (from pycocotools)\n",
            "  Using cached matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Collecting scipy>=1.10.0 (from albumentations)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from albumentations) (6.0.2)\n",
            "Collecting pydantic>=2.9.2 (from albumentations)\n",
            "  Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Collecting albucore==0.0.23 (from albumentations)\n",
            "  Using cached albucore-0.0.23-py3-none-any.whl (14 kB)\n",
            "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations)\n",
            "  Using cached stringzilla-3.11.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
            "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\n",
            "  Using cached simsimd-6.2.1.tar.gz (165 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib>=2.1.0->pycocotools)\n",
            "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=2.1.0->pycocotools)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=2.1.0->pycocotools)\n",
            "  Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=2.1.0->pycocotools)\n",
            "  Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Requirement already satisfied: packaging>=20.0 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Collecting pillow>=8 (from matplotlib>=2.1.0->pycocotools)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1 (from matplotlib>=2.1.0->pycocotools)\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic>=2.9.2->albumentations)\n",
            "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
            "Building wheels for collected packages: simsimd\n",
            "  Building wheel for simsimd (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for simsimd \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[30 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m running egg_info\n",
            "  \u001b[31m   \u001b[0m writing simsimd.egg-info/PKG-INFO\n",
            "  \u001b[31m   \u001b[0m writing dependency_links to simsimd.egg-info/dependency_links.txt\n",
            "  \u001b[31m   \u001b[0m writing top-level names to simsimd.egg-info/top_level.txt\n",
            "  \u001b[31m   \u001b[0m reading manifest file 'simsimd.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
            "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
            "  \u001b[31m   \u001b[0m writing manifest file 'simsimd.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/simsimd\n",
            "  \u001b[31m   \u001b[0m copying python/annotations/__init__.pyi -> build/lib.linux-x86_64-cpython-311/simsimd\n",
            "  \u001b[31m   \u001b[0m copying python/annotations/py.typed -> build/lib.linux-x86_64-cpython-311/simsimd\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m building 'simsimd' extension\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/c\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/python\n",
            "  \u001b[31m   \u001b[0m gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -I/usr/include/openssl11 -I/usr/include/openssl11 -I/opt/ohpc/pub/apps/python/3.11.4/include -fPIC -DSIMSIMD_NATIVE_F16=0 -DSIMSIMD_NATIVE_BF16=0 -DSIMSIMD_DYNAMIC_DISPATCH=1 -DSIMSIMD_TARGET_NEON=1 -DSIMSIMD_TARGET_NEON_F16=1 -DSIMSIMD_TARGET_NEON_BF16=1 -DSIMSIMD_TARGET_SVE=1 -DSIMSIMD_TARGET_SVE_F16=1 -DSIMSIMD_TARGET_SVE_BF16=1 -DSIMSIMD_TARGET_SVE2=1 -DSIMSIMD_TARGET_HASWELL=1 -DSIMSIMD_TARGET_SKYLAKE=1 -DSIMSIMD_TARGET_ICE=1 -DSIMSIMD_TARGET_GENOA=1 -DSIMSIMD_TARGET_SAPPHIRE=1 -DSIMSIMD_TARGET_TURIN=1 -DSIMSIMD_TARGET_SIERRA=0 -Iinclude -I/xdisk/ldbrown/maheshg/myenv/include -I/opt/ohpc/pub/apps/python/3.11.4/include/python3.11 -c c/lib.c -o build/temp.linux-x86_64-cpython-311/c/lib.o -std=c11 -O3 -ffast-math -fdiagnostics-color=always -fvisibility=default -fPIC -w -fopenmp\n",
            "  \u001b[31m   \u001b[0m In file included from \u001b[01m\u001b[Kinclude/simsimd/simsimd.h:105:0\u001b[m\u001b[K,\n",
            "  \u001b[31m   \u001b[0m                  from \u001b[01m\u001b[Kc/lib.c:54\u001b[m\u001b[K:\n",
            "  \u001b[31m   \u001b[0m \u001b[01m\u001b[Kinclude/simsimd/binary.h:267:9:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kattribute(target(\"avx512f\")) is unknown\n",
            "  \u001b[31m   \u001b[0m  #pragma GCC target(\"avx2\", \"avx512f\", \"avx512vl\", \"bmi2\", \"avx512bw\", \"avx512vpopcntdq\")\n",
            "  \u001b[31m   \u001b[0m \u001b[01;32m\u001b[K         ^\u001b[m\u001b[K\n",
            "  \u001b[31m   \u001b[0m \u001b[01m\u001b[Kinclude/simsimd/binary.h:267:9:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kattribute(target(\"avx512vl\")) is unknown\n",
            "  \u001b[31m   \u001b[0m \u001b[01m\u001b[Kinclude/simsimd/binary.h:267:9:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kattribute(target(\"avx512bw\")) is unknown\n",
            "  \u001b[31m   \u001b[0m \u001b[01m\u001b[Kinclude/simsimd/binary.h:267:9:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kattribute(target(\"avx512vpopcntdq\")) is unknown\n",
            "  \u001b[31m   \u001b[0m include/simsimd/binary.h:267: confused by earlier errors, bailing out\n",
            "  \u001b[31m   \u001b[0m Preprocessed source stored into /tmp/ccclAfb8.out file, please attach this to your bugreport.\n",
            "  \u001b[31m   \u001b[0m error: command '/bin/gcc' failed with exit code 1\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for simsimd\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build simsimd\n",
            "\u001b[31mERROR: Could not build wheels for simsimd, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pycocotools opencv-python numpy tqdm albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bd7FEY7dB2m",
        "outputId": "412a1efb-1a6c-4b21-9490-de73e73c1d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-18 01:04:34--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.30.92, 3.5.29.208, 3.5.29.228, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.30.92|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "100%[======================================>] 252,907,541 37.8MB/s   in 6.3s   \n",
            "\n",
            "2025-02-18 01:04:41 (38.1 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "--2025-02-18 01:04:41--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.231.113, 16.182.42.145, 52.216.8.91, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.231.113|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "100%[===================================>] 19,336,861,798 4.96MB/s   in 29m 3s \n",
            "\n",
            "2025-02-18 01:33:44 (10.6 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
            "\n",
            "--2025-02-18 01:33:44--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.24.33, 52.217.89.68, 52.217.142.233, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.24.33|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘val2017.zip’\n",
            "\n",
            "100%[======================================>] 815,585,330 4.81MB/s   in 2m 36s \n",
            "\n",
            "2025-02-18 01:36:21 (4.97 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n",
            "\n",
            "Archive:  annotations_trainval2017.zip\n",
            "  inflating: annotations/instances_train2017.json  \n",
            "  inflating: annotations/instances_val2017.json  \n",
            "  inflating: annotations/captions_train2017.json  \n",
            "  inflating: annotations/captions_val2017.json  \n",
            "  inflating: annotations/person_keypoints_train2017.json  "
          ]
        }
      ],
      "source": [
        "!mkdir coco\n",
        "!cd coco && wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!cd coco && wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!cd coco && wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!cd coco && unzip annotations_trainval2017.zip\n",
        "!cd coco && unzip train2017.zip\n",
        "!cd coco && unzip val2017.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2pCIk9ppZim",
        "outputId": "793bf4c1-fc2b-4339-8678-b6bb39ed089b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting albumentations==1.3.0\n",
            "  Using cached albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "Collecting numpy>=1.11.1 (from albumentations==1.3.0)\n",
            "  Using cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Collecting scipy (from albumentations==1.3.0)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Collecting scikit-image>=0.16.1 (from albumentations==1.3.0)\n",
            "  Downloading scikit_image-0.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from albumentations==1.3.0) (6.0.2)\n",
            "Collecting qudida>=0.0.4 (from albumentations==1.3.0)\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Collecting opencv-python-headless>=4.1.1 (from albumentations==1.3.0)\n",
            "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "Collecting scikit-learn>=0.19.1 (from qudida>=0.0.4->albumentations==1.3.0)\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.12.2)\n",
            "Collecting networkx>=3.0 (from scikit-image>=0.16.1->albumentations==1.3.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=10.1 (from scikit-image>=0.16.1->albumentations==1.3.0)\n",
            "  Using cached pillow-11.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "Collecting imageio!=2.35.0,>=2.33 (from scikit-image>=0.16.1->albumentations==1.3.0)\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tifffile>=2022.8.12 (from scikit-image>=0.16.1->albumentations==1.3.0)\n",
            "  Downloading tifffile-2025.1.10-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (24.2)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image>=0.16.1->albumentations==1.3.0)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=3.1.0 (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, pillow, numpy, networkx, lazy-loader, joblib, tifffile, scipy, opencv-python-headless, imageio, scikit-learn, scikit-image, qudida, albumentations\n",
            "Successfully installed albumentations-1.3.0 imageio-2.37.0 joblib-1.4.2 lazy-loader-0.4 networkx-3.4.2 numpy-2.2.3 opencv-python-headless-4.11.0.86 pillow-11.1.0 qudida-0.0.4 scikit-image-0.25.1 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0 tifffile-2025.1.10\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations==1.3.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKgYNL-6sUuv",
        "outputId": "adf10ed7-b9c3-4587-d45f-a6d8bccfc423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'RT-DETR'...\n",
            "remote: Enumerating objects: 1020, done.\u001b[K\n",
            "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 1020 (delta 145), reused 120 (delta 120), pack-reused 800 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1020/1020), 626.16 KiB | 0 bytes/s, done.\n",
            "Resolving deltas: 100% (496/496), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the RT-DETR repository\n",
        "!git clone https://github.com/lyuwenyu/RT-DETR.git\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kwWCbuT1lIFk",
        "outputId": "58e12480-8507-4c65-f15a-b808db7aa479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'RT-DETR'\n",
            "/xdisk/ldbrown/maheshg/mahesh1/RT-DETR\n"
          ]
        }
      ],
      "source": [
        "# Navigate into the RT-DETR directory\n",
        "%cd RT-DETR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/xdisk/ldbrown/maheshg/mahesh1/RT-DETR/rtdetr_pytorch\n",
            "Collecting torch==2.0.1 (from -r requirements.txt (line 1))\n",
            "  Using cached torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "Collecting torchvision==0.15.2 (from -r requirements.txt (line 2))\n",
            "  Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "Collecting onnx==1.14.0 (from -r requirements.txt (line 3))\n",
            "  Using cached onnx-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "Collecting onnxruntime==1.15.1 (from -r requirements.txt (line 4))\n",
            "  Using cached onnxruntime-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Collecting pycocotools (from -r requirements.txt (line 5))\n",
            "  Using cached pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
            "Requirement already satisfied: PyYAML in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: scipy in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.15.2)\n",
            "Collecting transformers (from -r requirements.txt (line 8))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from torch==2.0.1->-r requirements.txt (line 1)) (4.12.2)\n",
            "Collecting sympy (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Requirement already satisfied: networkx in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from torch==2.0.1->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from torch==2.0.1->-r requirements.txt (line 1)) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "Requirement already satisfied: numpy in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from torchvision==0.15.2->-r requirements.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: requests in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from torchvision==0.15.2->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from torchvision==0.15.2->-r requirements.txt (line 2)) (11.1.0)\n",
            "Collecting protobuf>=3.20.2 (from onnx==1.14.0->-r requirements.txt (line 3))\n",
            "  Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.15.1->-r requirements.txt (line 4))\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Collecting flatbuffers (from onnxruntime==1.15.1->-r requirements.txt (line 4))\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: packaging in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from onnxruntime==1.15.1->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: setuptools in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 1)) (65.5.0)\n",
            "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached cmake-3.31.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Collecting matplotlib>=2.1.0 (from pycocotools->-r requirements.txt (line 5))\n",
            "  Using cached matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers->-r requirements.txt (line 8))\n",
            "  Using cached huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 8))\n",
            "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 8))\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Collecting safetensors>=0.4.1 (from transformers->-r requirements.txt (line 8))\n",
            "  Using cached safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
            "Collecting tqdm>=4.27 (from transformers->-r requirements.txt (line 8))\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers->-r requirements.txt (line 8))\n",
            "  Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 5))\n",
            "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 5))\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 5))\n",
            "  Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 5))\n",
            "  Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 5))\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.15.1->-r requirements.txt (line 4))\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1->-r requirements.txt (line 1))\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Requirement already satisfied: six>=1.5 in /xdisk/ldbrown/maheshg/myenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 5)) (1.17.0)\n",
            "Installing collected packages: mpmath, lit, flatbuffers, wheel, tqdm, sympy, safetensors, regex, pyparsing, protobuf, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, kiwisolver, humanfriendly, fsspec, fonttools, filelock, cycler, contourpy, cmake, onnx, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, matplotlib, huggingface-hub, coloredlogs, tokenizers, pycocotools, onnxruntime, nvidia-cusolver-cu11, nvidia-cudnn-cu11, transformers, triton, torch, torchvision\n",
            "Successfully installed cmake-3.31.4 coloredlogs-15.0.1 contourpy-1.3.1 cycler-0.12.1 filelock-3.17.0 flatbuffers-25.2.10 fonttools-4.56.0 fsspec-2025.2.0 huggingface-hub-0.28.1 humanfriendly-10.0 kiwisolver-1.4.8 lit-18.1.8 matplotlib-3.10.0 mpmath-1.3.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnx-1.14.0 onnxruntime-1.15.1 protobuf-5.29.3 pycocotools-2.0.8 pyparsing-3.2.1 regex-2024.11.6 safetensors-0.5.2 sympy-1.13.3 tokenizers-0.21.0 torch-2.0.1 torchvision-0.15.2 tqdm-4.67.1 transformers-4.49.0 triton-2.0.0 wheel-0.45.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Install the required packages\n",
        "%cd /xdisk/ldbrown/maheshg/mahesh1/RT-DETR/rtdetr_pytorch/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.3\n",
            "    Uninstalling numpy-2.2.3:\n",
            "      Successfully uninstalled numpy-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "onnxruntime 1.15.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W59RHpSxuskD",
        "outputId": "206f718c-3466-485a-946d-5bc963cb9d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not init distributed mode.\n",
            "Start training\n",
            "Load PResNet50 state_dict\n",
            "Initial lr:  [1e-05, 0.0001, 0.0001, 0.0001]\n",
            "loading annotations into memory...\n",
            "Done (t=16.40s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.55s)\n",
            "creating index...\n",
            "index created!\n",
            "number of params: 42862860\n",
            "Epoch: [0]  [    0/29571]  eta: 13:51:41  lr: 0.000010  loss: 45.5348 (45.5348)  loss_vfl: 0.3638 (0.3638)  loss_bbox: 1.6843 (1.6843)  loss_giou: 1.6462 (1.6462)  loss_vfl_aux_0: 0.3949 (0.3949)  loss_bbox_aux_0: 1.6850 (1.6850)  loss_giou_aux_0: 1.6462 (1.6462)  loss_vfl_aux_1: 0.3668 (0.3668)  loss_bbox_aux_1: 1.6641 (1.6641)  loss_giou_aux_1: 1.7075 (1.7075)  loss_vfl_aux_2: 0.3978 (0.3978)  loss_bbox_aux_2: 1.6897 (1.6897)  loss_giou_aux_2: 1.6450 (1.6450)  loss_vfl_aux_3: 0.4065 (0.4065)  loss_bbox_aux_3: 1.6693 (1.6693)  loss_giou_aux_3: 1.6771 (1.6771)  loss_vfl_aux_4: 0.4271 (0.4271)  loss_bbox_aux_4: 1.6881 (1.6881)  loss_giou_aux_4: 1.6434 (1.6434)  loss_vfl_aux_5: 0.2831 (0.2831)  loss_bbox_aux_5: 1.7949 (1.7949)  loss_giou_aux_5: 1.7971 (1.7971)  loss_vfl_dn_0: 0.9119 (0.9119)  loss_bbox_dn_0: 0.9830 (0.9830)  loss_giou_dn_0: 1.3218 (1.3218)  loss_vfl_dn_1: 0.8919 (0.8919)  loss_bbox_dn_1: 0.9830 (0.9830)  loss_giou_dn_1: 1.3218 (1.3218)  loss_vfl_dn_2: 0.9194 (0.9194)  loss_bbox_dn_2: 0.9830 (0.9830)  loss_giou_dn_2: 1.3218 (1.3218)  loss_vfl_dn_3: 0.9122 (0.9122)  loss_bbox_dn_3: 0.9830 (0.9830)  loss_giou_dn_3: 1.3218 (1.3218)  loss_vfl_dn_4: 0.8870 (0.8870)  loss_bbox_dn_4: 0.9830 (0.9830)  loss_giou_dn_4: 1.3218 (1.3218)  loss_vfl_dn_5: 0.9062 (0.9062)  loss_bbox_dn_5: 0.9830 (0.9830)  loss_giou_dn_5: 1.3218 (1.3218)  time: 1.6875  data: 0.4022  max mem: 3076\n",
            "Epoch: [0]  [  100/29571]  eta: 4:26:09  lr: 0.000010  loss: 36.8918 (42.5885)  loss_vfl: 0.6835 (0.6155)  loss_bbox: 0.8816 (1.3585)  loss_giou: 1.3539 (1.4732)  loss_vfl_aux_0: 0.6307 (0.5403)  loss_bbox_aux_0: 0.9132 (1.4639)  loss_giou_aux_0: 1.3719 (1.5193)  loss_vfl_aux_1: 0.6723 (0.5644)  loss_bbox_aux_1: 0.8690 (1.4233)  loss_giou_aux_1: 1.3634 (1.5051)  loss_vfl_aux_2: 0.6990 (0.5899)  loss_bbox_aux_2: 0.8949 (1.3963)  loss_giou_aux_2: 1.3560 (1.4945)  loss_vfl_aux_3: 0.7081 (0.6018)  loss_bbox_aux_3: 0.8722 (1.3804)  loss_giou_aux_3: 1.3462 (1.4841)  loss_vfl_aux_4: 0.7140 (0.6121)  loss_bbox_aux_4: 0.8840 (1.3695)  loss_giou_aux_4: 1.3378 (1.4754)  loss_vfl_aux_5: 0.6184 (0.5167)  loss_bbox_aux_5: 0.9737 (1.5314)  loss_giou_aux_5: 1.4256 (1.5445)  loss_vfl_dn_0: 0.5930 (0.6890)  loss_bbox_dn_0: 0.8095 (0.9880)  loss_giou_dn_0: 1.3249 (1.3186)  loss_vfl_dn_1: 0.5840 (0.6641)  loss_bbox_dn_1: 0.8088 (1.0019)  loss_giou_dn_1: 1.3234 (1.3256)  loss_vfl_dn_2: 0.5803 (0.6611)  loss_bbox_dn_2: 0.8100 (1.0173)  loss_giou_dn_2: 1.3236 (1.3331)  loss_vfl_dn_3: 0.5877 (0.6627)  loss_bbox_dn_3: 0.8098 (1.0323)  loss_giou_dn_3: 1.3216 (1.3408)  loss_vfl_dn_4: 0.5856 (0.6537)  loss_bbox_dn_4: 0.8088 (1.0436)  loss_giou_dn_4: 1.3214 (1.3484)  loss_vfl_dn_5: 0.5793 (0.6388)  loss_bbox_dn_5: 0.8070 (1.0541)  loss_giou_dn_5: 1.3216 (1.3556)  time: 0.5252  data: 0.0116  max mem: 5485\n",
            "Epoch: [0]  [  200/29571]  eta: 4:17:00  lr: 0.000010  loss: 37.8126 (40.0976)  loss_vfl: 1.0321 (0.7771)  loss_bbox: 0.6929 (1.0693)  loss_giou: 1.1342 (1.3628)  loss_vfl_aux_0: 0.8463 (0.6874)  loss_bbox_aux_0: 0.7910 (1.1540)  loss_giou_aux_0: 1.2623 (1.4111)  loss_vfl_aux_1: 0.9647 (0.7115)  loss_bbox_aux_1: 0.7618 (1.1243)  loss_giou_aux_1: 1.2307 (1.3976)  loss_vfl_aux_2: 0.9834 (0.7416)  loss_bbox_aux_2: 0.7336 (1.1010)  loss_giou_aux_2: 1.1735 (1.3862)  loss_vfl_aux_3: 1.0441 (0.7554)  loss_bbox_aux_3: 0.7169 (1.0870)  loss_giou_aux_3: 1.1576 (1.3757)  loss_vfl_aux_4: 1.0560 (0.7709)  loss_bbox_aux_4: 0.7049 (1.0773)  loss_giou_aux_4: 1.1445 (1.3663)  loss_vfl_aux_5: 0.7953 (0.6463)  loss_bbox_aux_5: 0.8217 (1.2097)  loss_giou_aux_5: 1.2880 (1.4407)  loss_vfl_dn_0: 0.5497 (0.6246)  loss_bbox_dn_0: 0.9128 (0.9479)  loss_giou_dn_0: 1.3179 (1.3195)  loss_vfl_dn_1: 0.5700 (0.6168)  loss_bbox_dn_1: 0.8970 (0.9513)  loss_giou_dn_1: 1.2927 (1.3177)  loss_vfl_dn_2: 0.5807 (0.6203)  loss_bbox_dn_2: 0.8887 (0.9573)  loss_giou_dn_2: 1.2742 (1.3207)  loss_vfl_dn_3: 0.5987 (0.6283)  loss_bbox_dn_3: 0.8844 (0.9633)  loss_giou_dn_3: 1.2687 (1.3265)  loss_vfl_dn_4: 0.5889 (0.6236)  loss_bbox_dn_4: 0.8824 (0.9685)  loss_giou_dn_4: 1.2719 (1.3332)  loss_vfl_dn_5: 0.6033 (0.6109)  loss_bbox_dn_5: 0.8830 (0.9735)  loss_giou_dn_5: 1.2833 (1.3405)  time: 0.5345  data: 0.0116  max mem: 5485\n",
            "Epoch: [0]  [  300/29571]  eta: 4:15:11  lr: 0.000010  loss: 35.6019 (39.0815)  loss_vfl: 1.0166 (0.8875)  loss_bbox: 0.5964 (0.9347)  loss_giou: 1.1292 (1.2909)  loss_vfl_aux_0: 0.8355 (0.7635)  loss_bbox_aux_0: 0.6522 (1.0290)  loss_giou_aux_0: 1.2512 (1.3551)  loss_vfl_aux_1: 0.9022 (0.8054)  loss_bbox_aux_1: 0.6451 (0.9926)  loss_giou_aux_1: 1.1806 (1.3334)  loss_vfl_aux_2: 0.9513 (0.8461)  loss_bbox_aux_2: 0.6039 (0.9641)  loss_giou_aux_2: 1.1491 (1.3137)  loss_vfl_aux_3: 0.9997 (0.8657)  loss_bbox_aux_3: 0.5909 (0.9509)  loss_giou_aux_3: 1.1392 (1.3027)  loss_vfl_aux_4: 1.0201 (0.8819)  loss_bbox_aux_4: 0.5959 (0.9418)  loss_giou_aux_4: 1.1314 (1.2935)  loss_vfl_aux_5: 0.7270 (0.7098)  loss_bbox_aux_5: 0.7423 (1.0870)  loss_giou_aux_5: 1.3006 (1.3930)  loss_vfl_dn_0: 0.4995 (0.5986)  loss_bbox_dn_0: 0.8614 (0.9294)  loss_giou_dn_0: 1.3039 (1.3143)  loss_vfl_dn_1: 0.5282 (0.6030)  loss_bbox_dn_1: 0.8611 (0.9257)  loss_giou_dn_1: 1.2659 (1.3079)  loss_vfl_dn_2: 0.5491 (0.6089)  loss_bbox_dn_2: 0.8685 (0.9273)  loss_giou_dn_2: 1.2658 (1.3110)  loss_vfl_dn_3: 0.5523 (0.6179)  loss_bbox_dn_3: 0.8695 (0.9308)  loss_giou_dn_3: 1.2672 (1.3179)  loss_vfl_dn_4: 0.5646 (0.6147)  loss_bbox_dn_4: 0.8664 (0.9346)  loss_giou_dn_4: 1.2738 (1.3245)  loss_vfl_dn_5: 0.5626 (0.6031)  loss_bbox_dn_5: 0.8656 (0.9383)  loss_giou_dn_5: 1.2762 (1.3313)  time: 0.5060  data: 0.0116  max mem: 5485\n",
            "Epoch: [0]  [  400/29571]  eta: 4:12:54  lr: 0.000010  loss: 33.7787 (38.4275)  loss_vfl: 0.9270 (0.9534)  loss_bbox: 0.5747 (0.8610)  loss_giou: 1.1668 (1.2480)  loss_vfl_aux_0: 0.8102 (0.8246)  loss_bbox_aux_0: 0.5991 (0.9490)  loss_giou_aux_0: 1.2514 (1.3107)  loss_vfl_aux_1: 0.8621 (0.8703)  loss_bbox_aux_1: 0.5797 (0.9119)  loss_giou_aux_1: 1.1910 (1.2864)  loss_vfl_aux_2: 0.8933 (0.9078)  loss_bbox_aux_2: 0.5823 (0.8865)  loss_giou_aux_2: 1.1802 (1.2676)  loss_vfl_aux_3: 0.9585 (0.9308)  loss_bbox_aux_3: 0.5787 (0.8753)  loss_giou_aux_3: 1.1590 (1.2580)  loss_vfl_aux_4: 0.9572 (0.9474)  loss_bbox_aux_4: 0.5734 (0.8672)  loss_giou_aux_4: 1.1550 (1.2498)  loss_vfl_aux_5: 0.7362 (0.7501)  loss_bbox_aux_5: 0.7053 (1.0161)  loss_giou_aux_5: 1.3249 (1.3610)  loss_vfl_dn_0: 0.5076 (0.5815)  loss_bbox_dn_0: 0.6583 (0.9144)  loss_giou_dn_0: 1.2829 (1.3068)  loss_vfl_dn_1: 0.5556 (0.5938)  loss_bbox_dn_1: 0.6452 (0.9051)  loss_giou_dn_1: 1.2301 (1.2982)  loss_vfl_dn_2: 0.5582 (0.6016)  loss_bbox_dn_2: 0.6373 (0.9044)  loss_giou_dn_2: 1.2094 (1.3001)  loss_vfl_dn_3: 0.5950 (0.6144)  loss_bbox_dn_3: 0.6384 (0.9060)  loss_giou_dn_3: 1.2015 (1.3058)  loss_vfl_dn_4: 0.6015 (0.6126)  loss_bbox_dn_4: 0.6374 (0.9084)  loss_giou_dn_4: 1.2039 (1.3114)  loss_vfl_dn_5: 0.5899 (0.6019)  loss_bbox_dn_5: 0.6386 (0.9112)  loss_giou_dn_5: 1.2032 (1.3173)  time: 0.5159  data: 0.0116  max mem: 5485\n",
            "Epoch: [0]  [  500/29571]  eta: 4:11:55  lr: 0.000010  loss: 33.7423 (37.8120)  loss_vfl: 1.1762 (1.0104)  loss_bbox: 0.5187 (0.7984)  loss_giou: 0.9896 (1.2065)  loss_vfl_aux_0: 1.0218 (0.8658)  loss_bbox_aux_0: 0.5572 (0.8853)  loss_giou_aux_0: 1.1130 (1.2733)  loss_vfl_aux_1: 0.9940 (0.9196)  loss_bbox_aux_1: 0.5476 (0.8479)  loss_giou_aux_1: 1.0151 (1.2451)  loss_vfl_aux_2: 1.1535 (0.9589)  loss_bbox_aux_2: 0.5381 (0.8223)  loss_giou_aux_2: 1.0095 (1.2264)  loss_vfl_aux_3: 1.1523 (0.9868)  loss_bbox_aux_3: 0.5211 (0.8114)  loss_giou_aux_3: 1.0180 (1.2158)  loss_vfl_aux_4: 1.2197 (1.0028)  loss_bbox_aux_4: 0.5275 (0.8045)  loss_giou_aux_4: 0.9934 (1.2083)  loss_vfl_aux_5: 0.8808 (0.7806)  loss_bbox_aux_5: 0.6041 (0.9590)  loss_giou_aux_5: 1.1615 (1.3324)  loss_vfl_dn_0: 0.5156 (0.5698)  loss_bbox_dn_0: 0.7627 (0.9016)  loss_giou_dn_0: 1.2275 (1.2945)  loss_vfl_dn_1: 0.5807 (0.5904)  loss_bbox_dn_1: 0.7378 (0.8880)  loss_giou_dn_1: 1.1905 (1.2806)  loss_vfl_dn_2: 0.5917 (0.6009)  loss_bbox_dn_2: 0.7364 (0.8853)  loss_giou_dn_2: 1.1540 (1.2796)  loss_vfl_dn_3: 0.6258 (0.6137)  loss_bbox_dn_3: 0.7364 (0.8857)  loss_giou_dn_3: 1.1425 (1.2842)  loss_vfl_dn_4: 0.6256 (0.6131)  loss_bbox_dn_4: 0.7394 (0.8873)  loss_giou_dn_4: 1.1413 (1.2889)  loss_vfl_dn_5: 0.6512 (0.6034)  loss_bbox_dn_5: 0.7442 (0.8895)  loss_giou_dn_5: 1.1407 (1.2940)  time: 0.5325  data: 0.0116  max mem: 5485\n",
            "Epoch: [0]  [  600/29571]  eta: 4:10:05  lr: 0.000010  loss: 35.1947 (37.4838)  loss_vfl: 1.0213 (1.0620)  loss_bbox: 0.5874 (0.7605)  loss_giou: 1.0438 (1.1746)  loss_vfl_aux_0: 0.9223 (0.9054)  loss_bbox_aux_0: 0.6149 (0.8430)  loss_giou_aux_0: 1.1390 (1.2426)  loss_vfl_aux_1: 1.0035 (0.9649)  loss_bbox_aux_1: 0.5967 (0.8057)  loss_giou_aux_1: 1.0786 (1.2126)  loss_vfl_aux_2: 1.0370 (1.0067)  loss_bbox_aux_2: 0.5781 (0.7824)  loss_giou_aux_2: 1.0559 (1.1941)  loss_vfl_aux_3: 1.0384 (1.0376)  loss_bbox_aux_3: 0.5915 (0.7722)  loss_giou_aux_3: 1.0391 (1.1834)  loss_vfl_aux_4: 1.0224 (1.0510)  loss_bbox_aux_4: 0.5851 (0.7660)  loss_giou_aux_4: 1.0299 (1.1761)  loss_vfl_aux_5: 0.7854 (0.8129)  loss_bbox_aux_5: 0.7583 (0.9212)  loss_giou_aux_5: 1.2473 (1.3083)  loss_vfl_dn_0: 0.5319 (0.5632)  loss_bbox_dn_0: 0.7602 (0.9019)  loss_giou_dn_0: 1.2264 (1.2814)  loss_vfl_dn_1: 0.5984 (0.5900)  loss_bbox_dn_1: 0.7528 (0.8841)  loss_giou_dn_1: 1.1509 (1.2614)  loss_vfl_dn_2: 0.6432 (0.6036)  loss_bbox_dn_2: 0.7509 (0.8792)  loss_giou_dn_2: 1.1147 (1.2573)  loss_vfl_dn_3: 0.6540 (0.6185)  loss_bbox_dn_3: 0.7505 (0.8785)  loss_giou_dn_3: 1.0992 (1.2600)  loss_vfl_dn_4: 0.6522 (0.6188)  loss_bbox_dn_4: 0.7524 (0.8795)  loss_giou_dn_4: 1.0948 (1.2636)  loss_vfl_dn_5: 0.6555 (0.6102)  loss_bbox_dn_5: 0.7527 (0.8814)  loss_giou_dn_5: 1.0953 (1.2681)  time: 0.5171  data: 0.0116  max mem: 5485\n",
            "Epoch: [0]  [  700/29571]  eta: 4:08:43  lr: 0.000010  loss: 34.3636 (37.1166)  loss_vfl: 1.2701 (1.0913)  loss_bbox: 0.4551 (0.7306)  loss_giou: 0.9630 (1.1518)  loss_vfl_aux_0: 1.1123 (0.9291)  loss_bbox_aux_0: 0.5164 (0.8128)  loss_giou_aux_0: 1.0613 (1.2231)  loss_vfl_aux_1: 1.1826 (0.9912)  loss_bbox_aux_1: 0.4723 (0.7746)  loss_giou_aux_1: 0.9713 (1.1904)  loss_vfl_aux_2: 1.2201 (1.0320)  loss_bbox_aux_2: 0.4622 (0.7523)  loss_giou_aux_2: 0.9952 (1.1712)  loss_vfl_aux_3: 1.2723 (1.0646)  loss_bbox_aux_3: 0.4730 (0.7415)  loss_giou_aux_3: 0.9852 (1.1607)  loss_vfl_aux_4: 1.2803 (1.0787)  loss_bbox_aux_4: 0.4727 (0.7359)  loss_giou_aux_4: 0.9689 (1.1534)  loss_vfl_aux_5: 0.8975 (0.8316)  loss_bbox_aux_5: 0.6776 (0.8923)  loss_giou_aux_5: 1.1424 (1.2947)  loss_vfl_dn_0: 0.5136 (0.5564)  loss_bbox_dn_0: 0.7259 (0.8917)  loss_giou_dn_0: 1.1790 (1.2708)  loss_vfl_dn_1: 0.5687 (0.5886)  loss_bbox_dn_1: 0.6645 (0.8700)  loss_giou_dn_1: 1.0884 (1.2466)  loss_vfl_dn_2: 0.6154 (0.6042)  loss_bbox_dn_2: 0.6351 (0.8636)  loss_giou_dn_2: 1.0474 (1.2402)  loss_vfl_dn_3: 0.6570 (0.6209)  loss_bbox_dn_3: 0.6279 (0.8623)  loss_giou_dn_3: 1.0362 (1.2417)  loss_vfl_dn_4: 0.6495 (0.6213)  loss_bbox_dn_4: 0.6286 (0.8629)  loss_giou_dn_4: 1.0344 (1.2446)  loss_vfl_dn_5: 0.6516 (0.6139)  loss_bbox_dn_5: 0.6283 (0.8646)  loss_giou_dn_5: 1.0387 (1.2487)  time: 0.5150  data: 0.0118  max mem: 5485\n",
            "Epoch: [0]  [  800/29571]  eta: 4:07:42  lr: 0.000010  loss: 34.6494 (36.8008)  loss_vfl: 1.2101 (1.1178)  loss_bbox: 0.5961 (0.7055)  loss_giou: 0.9791 (1.1327)  loss_vfl_aux_0: 1.0492 (0.9465)  loss_bbox_aux_0: 0.6671 (0.7878)  loss_giou_aux_0: 1.1203 (1.2070)  loss_vfl_aux_1: 1.1586 (1.0121)  loss_bbox_aux_1: 0.6464 (0.7481)  loss_giou_aux_1: 1.0398 (1.1717)  loss_vfl_aux_2: 1.1675 (1.0547)  loss_bbox_aux_2: 0.6224 (0.7265)  loss_giou_aux_2: 1.0251 (1.1522)  loss_vfl_aux_3: 1.2341 (1.0886)  loss_bbox_aux_3: 0.6051 (0.7159)  loss_giou_aux_3: 0.9907 (1.1420)  loss_vfl_aux_4: 1.2086 (1.1041)  loss_bbox_aux_4: 0.6104 (0.7106)  loss_giou_aux_4: 0.9801 (1.1346)  loss_vfl_aux_5: 0.9503 (0.8458)  loss_bbox_aux_5: 0.7164 (0.8711)  loss_giou_aux_5: 1.1726 (1.2846)  loss_vfl_dn_0: 0.4909 (0.5506)  loss_bbox_dn_0: 0.9446 (0.8837)  loss_giou_dn_0: 1.1678 (1.2605)  loss_vfl_dn_1: 0.5592 (0.5866)  loss_bbox_dn_1: 0.7716 (0.8585)  loss_giou_dn_1: 1.1100 (1.2319)  loss_vfl_dn_2: 0.5946 (0.6043)  loss_bbox_dn_2: 0.7205 (0.8509)  loss_giou_dn_2: 1.0802 (1.2236)  loss_vfl_dn_3: 0.6208 (0.6220)  loss_bbox_dn_3: 0.6826 (0.8490)  loss_giou_dn_3: 1.0896 (1.2241)  loss_vfl_dn_4: 0.6319 (0.6226)  loss_bbox_dn_4: 0.6626 (0.8493)  loss_giou_dn_4: 1.0851 (1.2265)  loss_vfl_dn_5: 0.6317 (0.6160)  loss_bbox_dn_5: 0.6571 (0.8507)  loss_giou_dn_5: 1.0861 (1.2302)  time: 0.5397  data: 0.0117  max mem: 5485\n",
            "Epoch: [0]  [  900/29571]  eta: 4:06:00  lr: 0.000010  loss: 31.7750 (36.4310)  loss_vfl: 1.3293 (1.1409)  loss_bbox: 0.3736 (0.6776)  loss_giou: 0.8159 (1.1104)  loss_vfl_aux_0: 1.1404 (0.9655)  loss_bbox_aux_0: 0.4580 (0.7608)  loss_giou_aux_0: 0.9270 (1.1865)  loss_vfl_aux_1: 1.1704 (1.0336)  loss_bbox_aux_1: 0.4206 (0.7192)  loss_giou_aux_1: 0.8877 (1.1491)  loss_vfl_aux_2: 1.1612 (1.0766)  loss_bbox_aux_2: 0.4055 (0.6977)  loss_giou_aux_2: 0.8734 (1.1295)  loss_vfl_aux_3: 1.2809 (1.1105)  loss_bbox_aux_3: 0.3822 (0.6878)  loss_giou_aux_3: 0.8468 (1.1194)  loss_vfl_aux_4: 1.3106 (1.1262)  loss_bbox_aux_4: 0.3810 (0.6825)  loss_giou_aux_4: 0.8325 (1.1123)  loss_vfl_aux_5: 0.9914 (0.8609)  loss_bbox_aux_5: 0.5351 (0.8482)  loss_giou_aux_5: 1.1126 (1.2720)  loss_vfl_dn_0: 0.5019 (0.5453)  loss_bbox_dn_0: 0.6433 (0.8737)  loss_giou_dn_0: 1.1773 (1.2507)  loss_vfl_dn_1: 0.5747 (0.5843)  loss_bbox_dn_1: 0.6084 (0.8454)  loss_giou_dn_1: 1.1068 (1.2180)  loss_vfl_dn_2: 0.6006 (0.6042)  loss_bbox_dn_2: 0.6072 (0.8367)  loss_giou_dn_2: 1.0771 (1.2075)  loss_vfl_dn_3: 0.6102 (0.6233)  loss_bbox_dn_3: 0.6038 (0.8345)  loss_giou_dn_3: 1.0510 (1.2069)  loss_vfl_dn_4: 0.6178 (0.6240)  loss_bbox_dn_4: 0.6052 (0.8345)  loss_giou_dn_4: 1.0415 (1.2087)  loss_vfl_dn_5: 0.6219 (0.6184)  loss_bbox_dn_5: 0.6047 (0.8358)  loss_giou_dn_5: 1.0420 (1.2122)  time: 0.4911  data: 0.0118  max mem: 5485\n",
            "Epoch: [0]  [ 1000/29571]  eta: 4:04:48  lr: 0.000010  loss: 31.9784 (36.1375)  loss_vfl: 1.0167 (1.1574)  loss_bbox: 0.4497 (0.6570)  loss_giou: 1.0072 (1.0916)  loss_vfl_aux_0: 0.8522 (0.9781)  loss_bbox_aux_0: 0.5508 (0.7421)  loss_giou_aux_0: 1.0575 (1.1703)  loss_vfl_aux_1: 0.8826 (1.0463)  loss_bbox_aux_1: 0.5025 (0.6993)  loss_giou_aux_1: 1.0482 (1.1316)  loss_vfl_aux_2: 0.9517 (1.0910)  loss_bbox_aux_2: 0.5114 (0.6775)  loss_giou_aux_2: 1.0290 (1.1109)  loss_vfl_aux_3: 0.9544 (1.1254)  loss_bbox_aux_3: 0.4662 (0.6672)  loss_giou_aux_3: 1.0128 (1.1008)  loss_vfl_aux_4: 0.9921 (1.1416)  loss_bbox_aux_4: 0.4666 (0.6621)  loss_giou_aux_4: 1.0121 (1.0938)  loss_vfl_aux_5: 0.6819 (0.8717)  loss_bbox_aux_5: 0.6545 (0.8340)  loss_giou_aux_5: 1.2071 (1.2616)  loss_vfl_dn_0: 0.4706 (0.5407)  loss_bbox_dn_0: 0.7179 (0.8675)  loss_giou_dn_0: 1.1827 (1.2422)  loss_vfl_dn_1: 0.5221 (0.5811)  loss_bbox_dn_1: 0.7060 (0.8373)  loss_giou_dn_1: 1.1198 (1.2066)  loss_vfl_dn_2: 0.5630 (0.6026)  loss_bbox_dn_2: 0.6921 (0.8279)  loss_giou_dn_2: 1.0973 (1.1946)  loss_vfl_dn_3: 0.6011 (0.6222)  loss_bbox_dn_3: 0.6872 (0.8254)  loss_giou_dn_3: 1.0858 (1.1929)  loss_vfl_dn_4: 0.5974 (0.6230)  loss_bbox_dn_4: 0.6850 (0.8254)  loss_giou_dn_4: 1.0913 (1.1944)  loss_vfl_dn_5: 0.5862 (0.6185)  loss_bbox_dn_5: 0.6847 (0.8265)  loss_giou_dn_5: 1.0937 (1.1976)  time: 0.5209  data: 0.0116  max mem: 5485\n",
            "Epoch: [0]  [ 1100/29571]  eta: 4:03:34  lr: 0.000010  loss: 32.6898 (35.8534)  loss_vfl: 1.2411 (1.1743)  loss_bbox: 0.4180 (0.6377)  loss_giou: 0.8442 (1.0723)  loss_vfl_aux_0: 1.0337 (0.9934)  loss_bbox_aux_0: 0.5189 (0.7237)  loss_giou_aux_0: 0.9572 (1.1531)  loss_vfl_aux_1: 1.1362 (1.0629)  loss_bbox_aux_1: 0.4686 (0.6795)  loss_giou_aux_1: 0.9105 (1.1129)  loss_vfl_aux_2: 1.1204 (1.1069)  loss_bbox_aux_2: 0.4090 (0.6581)  loss_giou_aux_2: 0.8763 (1.0919)  loss_vfl_aux_3: 1.2182 (1.1419)  loss_bbox_aux_3: 0.4176 (0.6482)  loss_giou_aux_3: 0.8626 (1.0813)  loss_vfl_aux_4: 1.2038 (1.1580)  loss_bbox_aux_4: 0.4229 (0.6427)  loss_giou_aux_4: 0.8477 (1.0744)  loss_vfl_aux_5: 0.8963 (0.8866)  loss_bbox_aux_5: 0.6031 (0.8188)  loss_giou_aux_5: 1.0859 (1.2482)  loss_vfl_dn_0: 0.4767 (0.5362)  loss_bbox_dn_0: 0.7342 (0.8613)  loss_giou_dn_0: 1.1490 (1.2343)  loss_vfl_dn_1: 0.5343 (0.5782)  loss_bbox_dn_1: 0.6828 (0.8286)  loss_giou_dn_1: 1.0893 (1.1955)  loss_vfl_dn_2: 0.5807 (0.6010)  loss_bbox_dn_2: 0.6781 (0.8182)  loss_giou_dn_2: 1.0667 (1.1818)  loss_vfl_dn_3: 0.5947 (0.6215)  loss_bbox_dn_3: 0.6823 (0.8155)  loss_giou_dn_3: 1.0602 (1.1790)  loss_vfl_dn_4: 0.5783 (0.6224)  loss_bbox_dn_4: 0.6820 (0.8152)  loss_giou_dn_4: 1.0697 (1.1801)  loss_vfl_dn_5: 0.5840 (0.6185)  loss_bbox_dn_5: 0.6824 (0.8163)  loss_giou_dn_5: 1.0705 (1.1831)  time: 0.4824  data: 0.0114  max mem: 5485\n",
            "Epoch: [0]  [ 1200/29571]  eta: 4:02:38  lr: 0.000010  loss: 30.9727 (35.5449)  loss_vfl: 1.2494 (1.1879)  loss_bbox: 0.4160 (0.6197)  loss_giou: 0.9022 (1.0549)  loss_vfl_aux_0: 1.0131 (1.0058)  loss_bbox_aux_0: 0.4877 (0.7049)  loss_giou_aux_0: 0.9666 (1.1363)  loss_vfl_aux_1: 1.0885 (1.0756)  loss_bbox_aux_1: 0.4496 (0.6608)  loss_giou_aux_1: 0.9135 (1.0953)  loss_vfl_aux_2: 1.1362 (1.1198)  loss_bbox_aux_2: 0.4232 (0.6396)  loss_giou_aux_2: 0.8960 (1.0742)  loss_vfl_aux_3: 1.1948 (1.1548)  loss_bbox_aux_3: 0.4085 (0.6299)  loss_giou_aux_3: 0.9245 (1.0637)  loss_vfl_aux_4: 1.2366 (1.1710)  loss_bbox_aux_4: 0.4192 (0.6247)  loss_giou_aux_4: 0.8905 (1.0571)  loss_vfl_aux_5: 0.9873 (0.9019)  loss_bbox_aux_5: 0.5991 (0.8009)  loss_giou_aux_5: 1.0981 (1.2346)  loss_vfl_dn_0: 0.4833 (0.5324)  loss_bbox_dn_0: 0.6524 (0.8517)  loss_giou_dn_0: 1.1539 (1.2263)  loss_vfl_dn_1: 0.5338 (0.5758)  loss_bbox_dn_1: 0.6012 (0.8171)  loss_giou_dn_1: 1.0568 (1.1838)  loss_vfl_dn_2: 0.5828 (0.5998)  loss_bbox_dn_2: 0.5742 (0.8061)  loss_giou_dn_2: 1.0113 (1.1682)  loss_vfl_dn_3: 0.6251 (0.6213)  loss_bbox_dn_3: 0.5636 (0.8031)  loss_giou_dn_3: 0.9749 (1.1644)  loss_vfl_dn_4: 0.6359 (0.6227)  loss_bbox_dn_4: 0.5584 (0.8028)  loss_giou_dn_4: 0.9803 (1.1650)  loss_vfl_dn_5: 0.6250 (0.6194)  loss_bbox_dn_5: 0.5580 (0.8037)  loss_giou_dn_5: 0.9816 (1.1679)  time: 0.4998  data: 0.0115  max mem: 5485\n",
            "Epoch: [0]  [ 1300/29571]  eta: 4:01:32  lr: 0.000010  loss: 31.3788 (35.3258)  loss_vfl: 1.3959 (1.2030)  loss_bbox: 0.3586 (0.6045)  loss_giou: 0.7498 (1.0396)  loss_vfl_aux_0: 1.0953 (1.0230)  loss_bbox_aux_0: 0.4659 (0.6886)  loss_giou_aux_0: 0.8661 (1.1214)  loss_vfl_aux_1: 1.1721 (1.0889)  loss_bbox_aux_1: 0.3909 (0.6454)  loss_giou_aux_1: 0.8098 (1.0807)  loss_vfl_aux_2: 1.2818 (1.1342)  loss_bbox_aux_2: 0.3543 (0.6241)  loss_giou_aux_2: 0.7647 (1.0592)  loss_vfl_aux_3: 1.2664 (1.1685)  loss_bbox_aux_3: 0.3588 (0.6145)  loss_giou_aux_3: 0.7517 (1.0489)  loss_vfl_aux_4: 1.3257 (1.1859)  loss_bbox_aux_4: 0.3590 (0.6095)  loss_giou_aux_4: 0.7480 (1.0421)  loss_vfl_aux_5: 1.0687 (0.9181)  loss_bbox_aux_5: 0.6224 (0.7878)  loss_giou_aux_5: 1.0331 (1.2238)  loss_vfl_dn_0: 0.5056 (0.5301)  loss_bbox_dn_0: 0.7357 (0.8450)  loss_giou_dn_0: 1.0964 (1.2191)  loss_vfl_dn_1: 0.5444 (0.5741)  loss_bbox_dn_1: 0.6427 (0.8089)  loss_giou_dn_1: 1.0112 (1.1739)  loss_vfl_dn_2: 0.5752 (0.5994)  loss_bbox_dn_2: 0.6209 (0.7975)  loss_giou_dn_2: 0.9744 (1.1570)  loss_vfl_dn_3: 0.6171 (0.6214)  loss_bbox_dn_3: 0.6234 (0.7944)  loss_giou_dn_3: 0.9625 (1.1524)  loss_vfl_dn_4: 0.6107 (0.6231)  loss_bbox_dn_4: 0.6251 (0.7940)  loss_giou_dn_4: 0.9623 (1.1530)  loss_vfl_dn_5: 0.6193 (0.6203)  loss_bbox_dn_5: 0.6249 (0.7950)  loss_giou_dn_5: 0.9617 (1.1557)  time: 0.4920  data: 0.0114  max mem: 5487\n",
            "Epoch: [0]  [ 1400/29571]  eta: 4:00:49  lr: 0.000010  loss: 32.7616 (35.1138)  loss_vfl: 1.2356 (1.2112)  loss_bbox: 0.3694 (0.5922)  loss_giou: 0.8030 (1.0271)  loss_vfl_aux_0: 1.1088 (1.0319)  loss_bbox_aux_0: 0.4406 (0.6761)  loss_giou_aux_0: 0.9086 (1.1101)  loss_vfl_aux_1: 1.2192 (1.0984)  loss_bbox_aux_1: 0.3836 (0.6323)  loss_giou_aux_1: 0.8583 (1.0681)  loss_vfl_aux_2: 1.2735 (1.1435)  loss_bbox_aux_2: 0.3848 (0.6112)  loss_giou_aux_2: 0.8348 (1.0464)  loss_vfl_aux_3: 1.2386 (1.1763)  loss_bbox_aux_3: 0.3720 (0.6018)  loss_giou_aux_3: 0.8236 (1.0362)  loss_vfl_aux_4: 1.2710 (1.1933)  loss_bbox_aux_4: 0.3618 (0.5972)  loss_giou_aux_4: 0.8194 (1.0296)  loss_vfl_aux_5: 1.1542 (0.9308)  loss_bbox_aux_5: 0.5883 (0.7770)  loss_giou_aux_5: 1.0221 (1.2140)  loss_vfl_dn_0: 0.4856 (0.5279)  loss_bbox_dn_0: 0.7934 (0.8409)  loss_giou_dn_0: 1.1191 (1.2120)  loss_vfl_dn_1: 0.5385 (0.5723)  loss_bbox_dn_1: 0.7019 (0.8031)  loss_giou_dn_1: 1.0396 (1.1640)  loss_vfl_dn_2: 0.5759 (0.5985)  loss_bbox_dn_2: 0.6777 (0.7912)  loss_giou_dn_2: 1.0023 (1.1460)  loss_vfl_dn_3: 0.5990 (0.6211)  loss_bbox_dn_3: 0.6498 (0.7879)  loss_giou_dn_3: 0.9848 (1.1406)  loss_vfl_dn_4: 0.6138 (0.6230)  loss_bbox_dn_4: 0.6406 (0.7874)  loss_giou_dn_4: 0.9849 (1.1409)  loss_vfl_dn_5: 0.6104 (0.6206)  loss_bbox_dn_5: 0.6396 (0.7882)  loss_giou_dn_5: 0.9850 (1.1434)  time: 0.5181  data: 0.0115  max mem: 5487\n",
            "Epoch: [0]  [ 1500/29571]  eta: 3:59:57  lr: 0.000010  loss: 31.7610 (34.8741)  loss_vfl: 1.2096 (1.2146)  loss_bbox: 0.3548 (0.5787)  loss_giou: 0.8000 (1.0166)  loss_vfl_aux_0: 1.1100 (1.0378)  loss_bbox_aux_0: 0.4309 (0.6617)  loss_giou_aux_0: 0.8738 (1.0998)  loss_vfl_aux_1: 1.1268 (1.1036)  loss_bbox_aux_1: 0.4061 (0.6181)  loss_giou_aux_1: 0.8766 (1.0576)  loss_vfl_aux_2: 1.1505 (1.1476)  loss_bbox_aux_2: 0.3620 (0.5975)  loss_giou_aux_2: 0.8269 (1.0358)  loss_vfl_aux_3: 1.1621 (1.1797)  loss_bbox_aux_3: 0.3673 (0.5882)  loss_giou_aux_3: 0.8267 (1.0256)  loss_vfl_aux_4: 1.1695 (1.1962)  loss_bbox_aux_4: 0.3543 (0.5836)  loss_giou_aux_4: 0.8210 (1.0191)  loss_vfl_aux_5: 1.0794 (0.9395)  loss_bbox_aux_5: 0.6446 (0.7636)  loss_giou_aux_5: 1.0042 (1.2057)  loss_vfl_dn_0: 0.4958 (0.5251)  loss_bbox_dn_0: 0.8817 (0.8340)  loss_giou_dn_0: 1.1022 (1.2072)  loss_vfl_dn_1: 0.5256 (0.5693)  loss_bbox_dn_1: 0.8250 (0.7950)  loss_giou_dn_1: 1.0093 (1.1573)  loss_vfl_dn_2: 0.5525 (0.5964)  loss_bbox_dn_2: 0.7928 (0.7828)  loss_giou_dn_2: 0.9687 (1.1383)  loss_vfl_dn_3: 0.5696 (0.6190)  loss_bbox_dn_3: 0.7808 (0.7794)  loss_giou_dn_3: 0.9527 (1.1326)  loss_vfl_dn_4: 0.5848 (0.6213)  loss_bbox_dn_4: 0.7683 (0.7788)  loss_giou_dn_4: 0.9430 (1.1327)  loss_vfl_dn_5: 0.5861 (0.6193)  loss_bbox_dn_5: 0.7689 (0.7796)  loss_giou_dn_5: 0.9428 (1.1351)  time: 0.5223  data: 0.0118  max mem: 5487\n",
            "Epoch: [0]  [ 1600/29571]  eta: 3:58:52  lr: 0.000010  loss: 30.4127 (34.6827)  loss_vfl: 1.1789 (1.2160)  loss_bbox: 0.3518 (0.5709)  loss_giou: 0.7726 (1.0076)  loss_vfl_aux_0: 1.1209 (1.0420)  loss_bbox_aux_0: 0.4161 (0.6530)  loss_giou_aux_0: 0.8846 (1.0907)  loss_vfl_aux_1: 1.1102 (1.1064)  loss_bbox_aux_1: 0.3832 (0.6100)  loss_giou_aux_1: 0.8084 (1.0483)  loss_vfl_aux_2: 1.1251 (1.1501)  loss_bbox_aux_2: 0.3543 (0.5893)  loss_giou_aux_2: 0.7794 (1.0266)  loss_vfl_aux_3: 1.1675 (1.1817)  loss_bbox_aux_3: 0.3580 (0.5799)  loss_giou_aux_3: 0.7825 (1.0166)  loss_vfl_aux_4: 1.1374 (1.1979)  loss_bbox_aux_4: 0.3521 (0.5755)  loss_giou_aux_4: 0.7745 (1.0101)  loss_vfl_aux_5: 1.1102 (0.9481)  loss_bbox_aux_5: 0.4861 (0.7547)  loss_giou_aux_5: 0.9883 (1.1981)  loss_vfl_dn_0: 0.4914 (0.5227)  loss_bbox_dn_0: 0.6913 (0.8295)  loss_giou_dn_0: 1.1094 (1.2020)  loss_vfl_dn_1: 0.5402 (0.5667)  loss_bbox_dn_1: 0.6339 (0.7892)  loss_giou_dn_1: 1.0270 (1.1500)  loss_vfl_dn_2: 0.5988 (0.5943)  loss_bbox_dn_2: 0.6101 (0.7766)  loss_giou_dn_2: 0.9619 (1.1301)  loss_vfl_dn_3: 0.6228 (0.6171)  loss_bbox_dn_3: 0.6016 (0.7731)  loss_giou_dn_3: 0.9470 (1.1240)  loss_vfl_dn_4: 0.6390 (0.6198)  loss_bbox_dn_4: 0.5946 (0.7725)  loss_giou_dn_4: 0.9416 (1.1238)  loss_vfl_dn_5: 0.6368 (0.6180)  loss_bbox_dn_5: 0.5939 (0.7733)  loss_giou_dn_5: 0.9427 (1.1261)  time: 0.4961  data: 0.0118  max mem: 5487\n",
            "Epoch: [0]  [ 1700/29571]  eta: 3:57:47  lr: 0.000010  loss: 29.0862 (34.4757)  loss_vfl: 1.2343 (1.2200)  loss_bbox: 0.3417 (0.5606)  loss_giou: 0.7143 (0.9969)  loss_vfl_aux_0: 1.0955 (1.0481)  loss_bbox_aux_0: 0.4350 (0.6425)  loss_giou_aux_0: 0.8127 (1.0802)  loss_vfl_aux_1: 1.1233 (1.1121)  loss_bbox_aux_1: 0.3915 (0.5995)  loss_giou_aux_1: 0.7436 (1.0377)  loss_vfl_aux_2: 1.1873 (1.1542)  loss_bbox_aux_2: 0.3463 (0.5790)  loss_giou_aux_2: 0.7305 (1.0157)  loss_vfl_aux_3: 1.1775 (1.1857)  loss_bbox_aux_3: 0.3539 (0.5694)  loss_giou_aux_3: 0.7184 (1.0057)  loss_vfl_aux_4: 1.2257 (1.2019)  loss_bbox_aux_4: 0.3405 (0.5650)  loss_giou_aux_4: 0.7140 (0.9994)  loss_vfl_aux_5: 1.0708 (0.9581)  loss_bbox_aux_5: 0.5408 (0.7451)  loss_giou_aux_5: 0.9839 (1.1892)  loss_vfl_dn_0: 0.4897 (0.5209)  loss_bbox_dn_0: 0.6583 (0.8248)  loss_giou_dn_0: 1.0423 (1.1964)  loss_vfl_dn_1: 0.5363 (0.5646)  loss_bbox_dn_1: 0.5704 (0.7829)  loss_giou_dn_1: 0.9574 (1.1422)  loss_vfl_dn_2: 0.5788 (0.5927)  loss_bbox_dn_2: 0.5299 (0.7696)  loss_giou_dn_2: 0.9158 (1.1212)  loss_vfl_dn_3: 0.6149 (0.6160)  loss_bbox_dn_3: 0.5200 (0.7659)  loss_giou_dn_3: 0.8815 (1.1146)  loss_vfl_dn_4: 0.6319 (0.6190)  loss_bbox_dn_4: 0.5134 (0.7652)  loss_giou_dn_4: 0.8718 (1.1142)  loss_vfl_dn_5: 0.6245 (0.6174)  loss_bbox_dn_5: 0.5133 (0.7659)  loss_giou_dn_5: 0.8743 (1.1163)  time: 0.4999  data: 0.0114  max mem: 5487\n",
            "Epoch: [0]  [ 1800/29571]  eta: 3:56:47  lr: 0.000010  loss: 30.1233 (34.2797)  loss_vfl: 1.0145 (1.2204)  loss_bbox: 0.3860 (0.5517)  loss_giou: 0.9442 (0.9891)  loss_vfl_aux_0: 0.9249 (1.0506)  loss_bbox_aux_0: 0.4199 (0.6335)  loss_giou_aux_0: 1.0914 (1.0730)  loss_vfl_aux_1: 0.9472 (1.1136)  loss_bbox_aux_1: 0.4255 (0.5904)  loss_giou_aux_1: 1.0126 (1.0303)  loss_vfl_aux_2: 0.9423 (1.1550)  loss_bbox_aux_2: 0.3875 (0.5700)  loss_giou_aux_2: 0.9843 (1.0083)  loss_vfl_aux_3: 0.9765 (1.1859)  loss_bbox_aux_3: 0.4006 (0.5604)  loss_giou_aux_3: 0.9725 (0.9980)  loss_vfl_aux_4: 0.9954 (1.2023)  loss_bbox_aux_4: 0.3938 (0.5560)  loss_giou_aux_4: 0.9582 (0.9918)  loss_vfl_aux_5: 0.9144 (0.9645)  loss_bbox_aux_5: 0.5332 (0.7372)  loss_giou_aux_5: 1.1227 (1.1833)  loss_vfl_dn_0: 0.4917 (0.5194)  loss_bbox_dn_0: 0.5518 (0.8186)  loss_giou_dn_0: 1.1430 (1.1919)  loss_vfl_dn_1: 0.5144 (0.5628)  loss_bbox_dn_1: 0.5130 (0.7754)  loss_giou_dn_1: 1.0438 (1.1359)  loss_vfl_dn_2: 0.5367 (0.5913)  loss_bbox_dn_2: 0.5060 (0.7617)  loss_giou_dn_2: 1.0066 (1.1141)  loss_vfl_dn_3: 0.5601 (0.6145)  loss_bbox_dn_3: 0.5024 (0.7577)  loss_giou_dn_3: 0.9855 (1.1070)  loss_vfl_dn_4: 0.5641 (0.6180)  loss_bbox_dn_4: 0.5020 (0.7570)  loss_giou_dn_4: 0.9887 (1.1064)  loss_vfl_dn_5: 0.5738 (0.6166)  loss_bbox_dn_5: 0.5028 (0.7577)  loss_giou_dn_5: 0.9890 (1.1085)  time: 0.5143  data: 0.0113  max mem: 5487\n",
            "Epoch: [0]  [ 1900/29571]  eta: 3:56:13  lr: 0.000010  loss: 30.2769 (34.0854)  loss_vfl: 1.1971 (1.2227)  loss_bbox: 0.3576 (0.5425)  loss_giou: 0.8633 (0.9806)  loss_vfl_aux_0: 0.9982 (1.0551)  loss_bbox_aux_0: 0.4088 (0.6238)  loss_giou_aux_0: 0.9337 (1.0645)  loss_vfl_aux_1: 1.1216 (1.1174)  loss_bbox_aux_1: 0.3926 (0.5807)  loss_giou_aux_1: 0.8921 (1.0216)  loss_vfl_aux_2: 1.1201 (1.1582)  loss_bbox_aux_2: 0.3769 (0.5604)  loss_giou_aux_2: 0.8110 (0.9997)  loss_vfl_aux_3: 1.2022 (1.1888)  loss_bbox_aux_3: 0.3804 (0.5511)  loss_giou_aux_3: 0.8087 (0.9894)  loss_vfl_aux_4: 1.1024 (1.2044)  loss_bbox_aux_4: 0.3629 (0.5468)  loss_giou_aux_4: 0.8578 (0.9834)  loss_vfl_aux_5: 0.9212 (0.9720)  loss_bbox_aux_5: 0.5467 (0.7270)  loss_giou_aux_5: 1.1116 (1.1762)  loss_vfl_dn_0: 0.4761 (0.5181)  loss_bbox_dn_0: 0.5291 (0.8114)  loss_giou_dn_0: 1.1201 (1.1878)  loss_vfl_dn_1: 0.5297 (0.5613)  loss_bbox_dn_1: 0.5009 (0.7669)  loss_giou_dn_1: 1.0165 (1.1298)  loss_vfl_dn_2: 0.5551 (0.5902)  loss_bbox_dn_2: 0.4929 (0.7529)  loss_giou_dn_2: 0.9793 (1.1074)  loss_vfl_dn_3: 0.5927 (0.6138)  loss_bbox_dn_3: 0.4933 (0.7488)  loss_giou_dn_3: 0.9523 (1.0997)  loss_vfl_dn_4: 0.6053 (0.6178)  loss_bbox_dn_4: 0.4901 (0.7480)  loss_giou_dn_4: 0.9482 (1.0989)  loss_vfl_dn_5: 0.6106 (0.6167)  loss_bbox_dn_5: 0.4906 (0.7487)  loss_giou_dn_5: 0.9489 (1.1009)  time: 0.4824  data: 0.0114  max mem: 5487\n",
            "Epoch: [0]  [ 2000/29571]  eta: 3:55:31  lr: 0.000010  loss: 29.4739 (33.9185)  loss_vfl: 1.3533 (1.2250)  loss_bbox: 0.3523 (0.5354)  loss_giou: 0.6783 (0.9715)  loss_vfl_aux_0: 1.1744 (1.0600)  loss_bbox_aux_0: 0.3943 (0.6162)  loss_giou_aux_0: 0.7313 (1.0552)  loss_vfl_aux_1: 1.2264 (1.1220)  loss_bbox_aux_1: 0.3945 (0.5731)  loss_giou_aux_1: 0.6774 (1.0120)  loss_vfl_aux_2: 1.3185 (1.1621)  loss_bbox_aux_2: 0.3801 (0.5530)  loss_giou_aux_2: 0.6692 (0.9904)  loss_vfl_aux_3: 1.3291 (1.1922)  loss_bbox_aux_3: 0.3581 (0.5438)  loss_giou_aux_3: 0.6632 (0.9802)  loss_vfl_aux_4: 1.2874 (1.2070)  loss_bbox_aux_4: 0.3624 (0.5397)  loss_giou_aux_4: 0.6802 (0.9742)  loss_vfl_aux_5: 1.2675 (0.9810)  loss_bbox_aux_5: 0.5089 (0.7197)  loss_giou_aux_5: 0.8745 (1.1683)  loss_vfl_dn_0: 0.4950 (0.5169)  loss_bbox_dn_0: 0.6864 (0.8075)  loss_giou_dn_0: 1.0404 (1.1829)  loss_vfl_dn_1: 0.5372 (0.5597)  loss_bbox_dn_1: 0.6361 (0.7619)  loss_giou_dn_1: 0.9404 (1.1231)  loss_vfl_dn_2: 0.5590 (0.5888)  loss_bbox_dn_2: 0.5939 (0.7473)  loss_giou_dn_2: 0.8926 (1.0998)  loss_vfl_dn_3: 0.5926 (0.6126)  loss_bbox_dn_3: 0.5929 (0.7430)  loss_giou_dn_3: 0.8825 (1.0917)  loss_vfl_dn_4: 0.6051 (0.6169)  loss_bbox_dn_4: 0.5964 (0.7422)  loss_giou_dn_4: 0.8814 (1.0907)  loss_vfl_dn_5: 0.6047 (0.6162)  loss_bbox_dn_5: 0.5965 (0.7428)  loss_giou_dn_5: 0.8826 (1.0926)  time: 0.5184  data: 0.0114  max mem: 5487\n",
            "Epoch: [0]  [ 2100/29571]  eta: 3:54:26  lr: 0.000010  loss: 30.6737 (33.7784)  loss_vfl: 1.3349 (1.2271)  loss_bbox: 0.3232 (0.5280)  loss_giou: 0.8134 (0.9650)  loss_vfl_aux_0: 1.1023 (1.0639)  loss_bbox_aux_0: 0.3961 (0.6088)  loss_giou_aux_0: 0.9125 (1.0488)  loss_vfl_aux_1: 1.1635 (1.1253)  loss_bbox_aux_1: 0.3652 (0.5656)  loss_giou_aux_1: 0.8725 (1.0055)  loss_vfl_aux_2: 1.1996 (1.1642)  loss_bbox_aux_2: 0.3561 (0.5456)  loss_giou_aux_2: 0.8559 (0.9840)  loss_vfl_aux_3: 1.2276 (1.1936)  loss_bbox_aux_3: 0.3380 (0.5363)  loss_giou_aux_3: 0.8313 (0.9737)  loss_vfl_aux_4: 1.2458 (1.2086)  loss_bbox_aux_4: 0.3305 (0.5322)  loss_giou_aux_4: 0.8209 (0.9680)  loss_vfl_aux_5: 0.9820 (0.9859)  loss_bbox_aux_5: 0.6112 (0.7136)  loss_giou_aux_5: 1.0907 (1.1636)  loss_vfl_dn_0: 0.5049 (0.5159)  loss_bbox_dn_0: 0.7337 (0.8047)  loss_giou_dn_0: 1.0949 (1.1787)  loss_vfl_dn_1: 0.5338 (0.5583)  loss_bbox_dn_1: 0.6188 (0.7582)  loss_giou_dn_1: 1.0070 (1.1175)  loss_vfl_dn_2: 0.5638 (0.5875)  loss_bbox_dn_2: 0.5653 (0.7433)  loss_giou_dn_2: 0.9639 (1.0937)  loss_vfl_dn_3: 0.5897 (0.6113)  loss_bbox_dn_3: 0.5753 (0.7389)  loss_giou_dn_3: 0.9520 (1.0852)  loss_vfl_dn_4: 0.6030 (0.6160)  loss_bbox_dn_4: 0.5778 (0.7380)  loss_giou_dn_4: 0.9521 (1.0841)  loss_vfl_dn_5: 0.5913 (0.6155)  loss_bbox_dn_5: 0.5780 (0.7386)  loss_giou_dn_5: 0.9524 (1.0859)  time: 0.5192  data: 0.0114  max mem: 5487\n",
            "Epoch: [0]  [ 2200/29571]  eta: 3:53:19  lr: 0.000010  loss: 29.5451 (33.6428)  loss_vfl: 1.1479 (1.2299)  loss_bbox: 0.3553 (0.5217)  loss_giou: 0.7722 (0.9570)  loss_vfl_aux_0: 1.1051 (1.0694)  loss_bbox_aux_0: 0.4467 (0.6020)  loss_giou_aux_0: 0.8673 (1.0410)  loss_vfl_aux_1: 1.1508 (1.1295)  loss_bbox_aux_1: 0.3751 (0.5591)  loss_giou_aux_1: 0.8037 (0.9976)  loss_vfl_aux_2: 1.1933 (1.1673)  loss_bbox_aux_2: 0.3450 (0.5392)  loss_giou_aux_2: 0.7914 (0.9760)  loss_vfl_aux_3: 1.1508 (1.1962)  loss_bbox_aux_3: 0.3423 (0.5300)  loss_giou_aux_3: 0.7783 (0.9657)  loss_vfl_aux_4: 1.1396 (1.2109)  loss_bbox_aux_4: 0.3692 (0.5259)  loss_giou_aux_4: 0.7784 (0.9600)  loss_vfl_aux_5: 1.0008 (0.9928)  loss_bbox_aux_5: 0.5422 (0.7083)  loss_giou_aux_5: 1.0390 (1.1575)  loss_vfl_dn_0: 0.4941 (0.5153)  loss_bbox_dn_0: 0.6903 (0.8023)  loss_giou_dn_0: 1.0762 (1.1740)  loss_vfl_dn_1: 0.5314 (0.5574)  loss_bbox_dn_1: 0.5984 (0.7547)  loss_giou_dn_1: 0.9774 (1.1111)  loss_vfl_dn_2: 0.5496 (0.5868)  loss_bbox_dn_2: 0.5733 (0.7394)  loss_giou_dn_2: 0.9356 (1.0866)  loss_vfl_dn_3: 0.5766 (0.6110)  loss_bbox_dn_3: 0.5546 (0.7348)  loss_giou_dn_3: 0.9144 (1.0777)  loss_vfl_dn_4: 0.5966 (0.6161)  loss_bbox_dn_4: 0.5546 (0.7339)  loss_giou_dn_4: 0.9091 (1.0764)  loss_vfl_dn_5: 0.6109 (0.6157)  loss_bbox_dn_5: 0.5551 (0.7344)  loss_giou_dn_5: 0.9082 (1.0782)  time: 0.4985  data: 0.0117  max mem: 5487\n",
            "Epoch: [0]  [ 2300/29571]  eta: 3:52:28  lr: 0.000010  loss: 30.7573 (33.5497)  loss_vfl: 1.0979 (1.2339)  loss_bbox: 0.3629 (0.5172)  loss_giou: 0.7994 (0.9493)  loss_vfl_aux_0: 1.0010 (1.0753)  loss_bbox_aux_0: 0.4744 (0.5978)  loss_giou_aux_0: 0.8705 (1.0335)  loss_vfl_aux_1: 1.0632 (1.1349)  loss_bbox_aux_1: 0.4150 (0.5548)  loss_giou_aux_1: 0.8329 (0.9898)  loss_vfl_aux_2: 1.0271 (1.1723)  loss_bbox_aux_2: 0.3834 (0.5348)  loss_giou_aux_2: 0.8219 (0.9681)  loss_vfl_aux_3: 1.0906 (1.2001)  loss_bbox_aux_3: 0.3822 (0.5256)  loss_giou_aux_3: 0.8082 (0.9581)  loss_vfl_aux_4: 1.0983 (1.2148)  loss_bbox_aux_4: 0.3631 (0.5213)  loss_giou_aux_4: 0.8026 (0.9523)  loss_vfl_aux_5: 0.9916 (1.0008)  loss_bbox_aux_5: 0.5743 (0.7054)  loss_giou_aux_5: 0.9880 (1.1513)  loss_vfl_dn_0: 0.5049 (0.5150)  loss_bbox_dn_0: 0.6983 (0.8024)  loss_giou_dn_0: 1.0965 (1.1694)  loss_vfl_dn_1: 0.5443 (0.5570)  loss_bbox_dn_1: 0.5871 (0.7538)  loss_giou_dn_1: 0.9940 (1.1047)  loss_vfl_dn_2: 0.5809 (0.5866)  loss_bbox_dn_2: 0.5678 (0.7380)  loss_giou_dn_2: 0.9481 (1.0794)  loss_vfl_dn_3: 0.6180 (0.6109)  loss_bbox_dn_3: 0.5533 (0.7334)  loss_giou_dn_3: 0.9359 (1.0702)  loss_vfl_dn_4: 0.6219 (0.6164)  loss_bbox_dn_4: 0.5449 (0.7324)  loss_giou_dn_4: 0.9250 (1.0688)  loss_vfl_dn_5: 0.6290 (0.6164)  loss_bbox_dn_5: 0.5440 (0.7329)  loss_giou_dn_5: 0.9277 (1.0704)  time: 0.5071  data: 0.0116  max mem: 5487\n"
          ]
        }
      ],
      "source": [
        "# Train RT-DETR using the modified configuration\n",
        "!python /xdisk/ldbrown/maheshg/mahesh1/RT-DETR/rtdetr_pytorch/tools/train.py -c /xdisk/ldbrown/maheshg/mahesh1/RT-DETR/rtdetr_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.4 ('myenv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "51dafbad9a036bb512030adf720d899755ad706096974461dd9717d7105ce485"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
